{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7kcXhxZ_cZG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUJgPUjZ6AYT"
      },
      "outputs": [],
      "source": [
        "# YouTube のビデオ ID を指定して wav をダウンロードする\n",
        "# https://github.com/yt-dlp/yt-dlp#embedding-yt-dlp\n",
        "!pip install yt-dlp\n",
        "from yt_dlp import YoutubeDL\n",
        "\n",
        "video_id = \"LjK_JqYF_t8\" # CHANGEME\n",
        "\n",
        "yt_dlp_opts = {\n",
        "  'outtmpl': '/content/drive/MyDrive/opt/nekuro-chat/youtube-video/%(id)s.%(ext)s',\n",
        "  'format': 'mp3/bestaudio/best',\n",
        "  'postprocessors': [{\n",
        "    'key': 'FFmpegExtractAudio',\n",
        "    'preferredcodec': 'wav',\n",
        "   }]\n",
        "}\n",
        "\n",
        "with YoutubeDL(yt_dlp_opts) as ydl:\n",
        "  ydl.download([\"https://www.youtube.com/watch?v=%s\" % video_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPANYfAvBRa-"
      },
      "outputs": [],
      "source": [
        "# 無音部分でファイルを分割する\n",
        "# https://github.com/jiaaro/pydub/\n",
        "# https://github.com/jiaaro/pydub/blob/master/API.markdown#silencesplit_on_silence\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment, silence\n",
        "\n",
        "video_id = \"LjK_JqYF_t8\" # CHANGEME\n",
        "\n",
        "file = AudioSegment.from_wav(\"/content/drive/MyDrive/opt/nekuro-chat/youtube-video/%s.wav\" % video_id)\n",
        "\n",
        "chunks = silence.split_on_silence(\n",
        "  file,\n",
        "  min_silence_len = 3000,\n",
        "  silence_thresh = -40,\n",
        "  seek_step = 1000,\n",
        ")\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "  print(chunk, chunk.duration_seconds) # ここのログを見ながらしきい値を調整する\n",
        "  if 10 <= chunk.duration_seconds <= 20:\n",
        "    print(\"export\", chunk.duration_seconds)\n",
        "    chunk.export(\"/content/drive/MyDrive/opt/nekuro-chat/youtube-video-chunk/%s_%04d.wav\" % (video_id, i + 1), format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTNGslMXA6ab"
      },
      "outputs": [],
      "source": [
        "# 音声ファイルをテキストに変換する\n",
        "# https://github.com/openai/whisper#python-usage\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "import whisper\n",
        "import os\n",
        "\n",
        "video_id = \"zMpnAQANC0Q\" # CHANGEME\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "for path in os.listdir(\".\"):\n",
        "  if not path.startswith(\"%s_\" % video_id):\n",
        "    continue\n",
        "\n",
        "  print(path)\n",
        "\n",
        "  result = model.transcribe(path)\n",
        "  print(result[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRWToMXGqIfb"
      },
      "outputs": [],
      "source": [
        "# japanrse single speaker speech dataset のテキストファイルのフォーマットを\n",
        "# tacotron2 のフォーマットに変換して保存する。\n",
        "\n",
        "!ls /content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset/transcript.txt\"\n",
        "output_path = \"/content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset/transcript_tacotron2.txt\"\n",
        "\n",
        "lines = []\n",
        "\n",
        "with open(input_path) as file:\n",
        "  for line in file.readlines():\n",
        "    columns = line.split(\"|\")\n",
        "    wav_path = columns[0]\n",
        "    ja_text = columns[1]\n",
        "    alphabet_text = columns[2]\n",
        "    duration_sec = columns[3]\n",
        "\n",
        "    replacer = {\n",
        "      '、': ',',\n",
        "      '。': '.',\n",
        "      '―': '',\n",
        "      '？': '',\n",
        "      '！': '',\n",
        "      ' ': '',\n",
        "    }\n",
        "\n",
        "    if float(duration_sec) <= 5:\n",
        "      continue\n",
        "\n",
        "    for key in replacer:\n",
        "      alphabet_text = alphabet_text.replace(key, replacer[key])\n",
        "\n",
        "    lines.append(\"%s|%s\\n\" % (wav_path.replace(\"meian/\", \"/content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset/meian_tacotron2/\"), alphabet_text))\n",
        "\n",
        "with open(output_path, \"w\") as file:\n",
        "  file.writelines(lines)\n",
        "\n",
        "!head /content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset/transcript_tacotron2.txt\n",
        "!wc  /content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset/transcript_tacotron2.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgbi1vsxswoJ"
      },
      "outputs": [],
      "source": [
        "# japanrse single speaker speech dataset のテキストファイルのフォーマットを\n",
        "# tacotron2 のフォーマットに変換して保存する。\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset/meian_tacotron2\n",
        "\n",
        "!pip install librosa\n",
        "!pip install pysoundfile\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "input_path = '/content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset/meian'\n",
        "output_path = '/content/drive/MyDrive/opt/nekuro-chat/japanese/japanese-single-speaker-speech-dataset/meian_tacotron2'\n",
        "\n",
        "input_files = os.listdir(input_path)\n",
        "\n",
        "for i, path in enumerate(input_files):\n",
        "   print(\"%d/%d %s\" % (i, len(input_files), path))\n",
        "   y, sr = librosa.core.load(\"%s/%s\" % (input_path, path), sr=22050, mono=True)\n",
        "   sf.write(\"%s/%s\" % (output_path, path), y, sr, subtype=\"PCM_16\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyN+FKxoOBSa7/6DntCSuWcK"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}